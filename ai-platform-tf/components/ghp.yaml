name: Get hyperparameter
inputs:
- {name: project_id, type: String}
- {name: job_name, type: String}
- {name: status, type: Boolean}
outputs:
- {name: model_depth, type: Integer}
- {name: dropout_rate, type: Float}
- {name: learning_rate, type: Float}
- {name: batch_size, type: Integer}
implementation:
  container:
    image: gcr.io/deeplearning-platform-release/tf2-gpu.2-1
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - "def get_hyperparameter(\n        project_id,\n        job_name, \n        status,\n\
      \    ):\n    from googleapiclient import discovery\n    import json\n    import\
      \ logging\n    import pandas as pd\n    from collections import namedtuple\n\
      \n    # Define the project id and the job id and format it for the api request\n\
      \    job_id = 'projects/{}/jobs/{}'.format(project_id, job_name)\n\n    # Build\
      \ the service\n    ml = discovery.build('ml', 'v1', cache_discovery=False)\n\
      \    # Execute the request and pass in the job id\n    request = ml.projects().jobs().get(name=job_id).execute()\n\
      \    logging.info(json.dumps(request, indent=4))\n    # Print response\n   \
      \ logging.info(json.dumps(request, indent=4))\n    trials = request['trainingOutput']['trials']\n\
      \    trials = pd.DataFrame(trials)\n    trials['hyperparameters.model_depth']\
      \ = trials['hyperparameters'].apply(lambda x: x['model_depth'])\n    trials['hyperparameters.dropout_rate']\
      \ = trials['hyperparameters'].apply(lambda x: x['dropout_rate'])\n    trials['hyperparameters.learning_rate']\
      \ = trials['hyperparameters'].apply(lambda x: x['learning_rate'])\n    trials['hyperparameters.batch_size']\
      \ = trials['hyperparameters'].apply(lambda x: x['batch_size'])\n    trials['finalMetric.trainingStep']\
      \ = trials['finalMetric'].apply(lambda x: x['trainingStep'])\n    trials['finalMetric.objectiveValue']\
      \ = trials['finalMetric'].apply(lambda x: x['objectiveValue'])\n    trials =\
      \ trials.sort_values(['finalMetric.objectiveValue'], ascending=False)\n\n  \
      \  model_depth=trials['hyperparameters'][0]['model_depth']\n    dropout_rate=trials['hyperparameters'][0]['dropout_rate']\n\
      \    learning_rate=trials['hyperparameters'][0]['learning_rate']\n    batch_size=trials['hyperparameters'][0]['batch_size']\n\
      \n    Ghp_Output = namedtuple('Ghp_Output',['model_depth', 'dropout_rate', 'learning_rate',\
      \ 'batch_size'])\n    return Ghp_Output(model_depth=model_depth, dropout_rate=dropout_rate,\
      \ learning_rate=learning_rate, batch_size=batch_size )  \n\ndef _serialize_float(float_value:\
      \ float) -> str:\n    if isinstance(float_value, str):\n        return float_value\n\
      \    if not isinstance(float_value, (float, int)):\n        raise TypeError('Value\
      \ \"{}\" has type \"{}\" instead of float.'.format(str(float_value), str(type(float_value))))\n\
      \    return str(float_value)\n\ndef _deserialize_bool(s) -> bool:\n    from\
      \ distutils.util import strtobool\n    return strtobool(s) == 1\n\ndef _serialize_int(int_value:\
      \ int) -> str:\n    if isinstance(int_value, str):\n        return int_value\n\
      \    if not isinstance(int_value, int):\n        raise TypeError('Value \"{}\"\
      \ has type \"{}\" instead of int.'.format(str(int_value), str(type(int_value))))\n\
      \    return str(int_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Get\
      \ hyperparameter', description='')\n_parser.add_argument(\"--project-id\", dest=\"\
      project_id\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --job-name\", dest=\"job_name\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--status\", dest=\"status\", type=_deserialize_bool,\
      \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\"\
      , dest=\"_output_paths\", type=str, nargs=4)\n_parsed_args = vars(_parser.parse_args())\n\
      _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = get_hyperparameter(**_parsed_args)\n\
      \n_output_serializers = [\n    _serialize_int,\n    _serialize_float,\n    _serialize_float,\n\
      \    _serialize_int,\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    args:
    - --project-id
    - {inputValue: project_id}
    - --job-name
    - {inputValue: job_name}
    - --status
    - {inputValue: status}
    - '----output-paths'
    - {outputPath: model_depth}
    - {outputPath: dropout_rate}
    - {outputPath: learning_rate}
    - {outputPath: batch_size}
