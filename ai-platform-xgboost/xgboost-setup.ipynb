{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ============================================================================== \\\n",
    " Copyright 2020 Google LLC. This software is provided as-is, without warranty \\\n",
    " or representation for any use or purpose. Your use of it is subject to your \\\n",
    " agreement with Google. \\\n",
    " ============================================================================== \n",
    " \n",
    " Author: Elvin Zhu, Chanchal Chatterjee \\\n",
    " Email: elvinzhu@google.com \\\n",
    "<img src=\"img/google-cloud-icon.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install pakcages requried for training, deployment and prediction with ai platform.\n",
    "\n",
    "https://cloud.google.com/ai-platform/training/docs/runtime-version-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/tuti-repo/ai-platform-xgboost\n",
    "python3 -m pip install -r ./requirements.txt --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training application package\n",
    "\n",
    "The easiest (and recommended) way to create a training application package uses gcloud to package and upload the application when you submit your training job. This method allows you to create a very simple file structure. For this tutorial, the file structure of your training application package should appear similar to the following:\n",
    "\n",
    "```\n",
    "config/\n",
    "    config.yaml\n",
    "    config_hpt.yaml\n",
    "    \n",
    "trainer/ \n",
    "    __init__.py\n",
    "    train.py\n",
    "    train_hpt.py\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./setup.py\n",
    "\n",
    "# python3\n",
    "# ==============================================================================\n",
    "# Copyright 2020 Google LLC. This software is provided as-is, without warranty\n",
    "# or representation for any use or purpose. Your use of it is subject to your\n",
    "# agreement with Google.\n",
    "# ==============================================================================\n",
    "\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "    'tensorflow==2.1.0',\n",
    "    'numpy==1.18.0',\n",
    "    'pandas==1.2.1',\n",
    "    'scipy==1.4.1',\n",
    "    'scikit-learn==0.22',\n",
    "    'google-cloud-storage==1.23.0',\n",
    "    'xgboost==1.3.3',\n",
    "    'cloudml-hypertune',\n",
    "    ]\n",
    " \n",
    "setup(\n",
    "    name='trainer',\n",
    "    version='0.1',\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='Trainer package for XGBoost Task'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./trainer/__init__.py\n",
    "\n",
    "# python3\n",
    "# ==============================================================================\n",
    "# Copyright 2020 Google LLC. This software is provided as-is, without warranty\n",
    "# or representation for any use or purpose. Your use of it is subject to your\n",
    "# agreement with Google.\n",
    "# ==============================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your training code (Example showed here is to use XGBoost to classify structured mortgage data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./trainer/train.py\n",
    "\n",
    "\n",
    "# python3\n",
    "# ==============================================================================\n",
    "# Copyright 2020 Google LLC. This software is provided as-is, without warranty\n",
    "# or representation for any use or purpose. Your use of it is subject to your\n",
    "# agreement with Google.\n",
    "# ==============================================================================\n",
    "\n",
    "import argparse\n",
    "import hypertune\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def train_xgboost(args):\n",
    "    \"\"\" Train a XGBoost model\n",
    "    Args:\n",
    "        args: structure with the following field:\n",
    "            bucket_name, str, gcs bucket name to store trained model\n",
    "            blob_name, str, gcs blob name to store trained model\n",
    "            train_feature_name, str, name of the train feature csv\n",
    "            train_label_name, str, name of train label csv\n",
    "            no_classes, int, number of prediction classes in the model\n",
    "            n_estimators, int, number of estimators (hypertune)\n",
    "            max_depth, int, maximum depth of trees (hypertune)\n",
    "            booster, str, type of boosters (hypertune)\n",
    "    Return:\n",
    "        xgboost model object\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x_train = pd.read_csv(args.train_feature_name)\n",
    "    y_train = pd.read_csv(args.train_label_name)\n",
    "   \n",
    "    # ---------------------------------------\n",
    "    # Train model\n",
    "    # ---------------------------------------\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': args.n_estimators,\n",
    "        'max_depth': args.max_depth,\n",
    "        'booster': args.booster,\n",
    "        'min_child_weight': 1,\n",
    "        'learning_rate': 0.1,\n",
    "        'gamma': 0,\n",
    "        'subsample': 1,\n",
    "        'colsample_bytree': 1,\n",
    "        'reg_alpha': 0,\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': args.no_classes,\n",
    "        }\n",
    "    xgb_model = XGBClassifier(**params, use_label_encoder=False)\n",
    "    xgb_model.fit(x_train, y_train)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Save the model to local\n",
    "    # ---------------------------------------\n",
    "\n",
    "    temp_name = './model.bst'\n",
    "    bst = xgb_model.get_booster()\n",
    "    bst.save_model(temp_name)\n",
    "    \n",
    "    # ---------------------------------------\n",
    "    # Move local model to gcs\n",
    "    # ---------------------------------------\n",
    "    \n",
    "    target_path = os.path.join(args.job_dir, 'model.bst')\n",
    "    if temp_name != target_path:\n",
    "        subprocess.check_call(['gsutil', 'cp', temp_name, target_path],\n",
    "            stderr=sys.stdout)\n",
    "\n",
    "    return xgb_model\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--job-dir\", type=str, help=\"Required by ai platform training\", default='./')\n",
    "    parser.add_argument(\"--train_feature_name\", type=str, help=\"Path to training feature csv file\")\n",
    "    parser.add_argument(\"--train_label_name\", type=str, help=\"Path to training label csv file\")\n",
    "    parser.add_argument(\"--no_classes\", type=int, help=\"Number of target classes in the label\")\n",
    "    parser.add_argument(\"--n_estimators\", type=int, help=\"Number of estimators in the xgboost model\")\n",
    "    parser.add_argument(\"--max_depth\", type=int, help=\"Maximum depth of trees in xgboost\")\n",
    "    parser.add_argument(\"--booster\", type=str, help=\"Type of booster\")\n",
    "    args = parser.parse_args()\n",
    "    model = train_xgboost(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another version of training script which implement metric reporting summary for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./trainer/train_hpt.py\n",
    "\n",
    "# python3\n",
    "# ==============================================================================\n",
    "# Copyright 2020 Google LLC. This software is provided as-is, without warranty\n",
    "# or representation for any use or purpose. Your use of it is subject to your\n",
    "# agreement with Google.\n",
    "# ==============================================================================\n",
    "\n",
    "import argparse\n",
    "import hypertune\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import hypertune\n",
    "\n",
    "def train_xgboost(args):\n",
    "    \"\"\" Train a XGBoost model\n",
    "    Args:\n",
    "        args: structure with the following field:\n",
    "            bucket_name, str, gcs bucket name to store trained model\n",
    "            blob_name, str, gcs blob name to store trained model\n",
    "            train_feature_name, str, name of the train feature csv\n",
    "            train_label_name, str, name of train label csv\n",
    "            no_classes, int, number of prediction classes in the model\n",
    "            n_estimators, int, number of estimators (hypertune)\n",
    "            max_depth, int, maximum depth of trees (hypertune)\n",
    "            booster, str, type of boosters (hypertune)\n",
    "    Return:\n",
    "        xgboost model object\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x_train = pd.read_csv(args.train_feature_name)\n",
    "    y_train = pd.read_csv(args.train_label_name)\n",
    "   \n",
    "    # ---------------------------------------\n",
    "    # Train model\n",
    "    # ---------------------------------------\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': args.n_estimators,\n",
    "        'max_depth': args.max_depth,\n",
    "        'booster': args.booster,\n",
    "        'min_child_weight': 1,\n",
    "        'learning_rate': 0.1,\n",
    "        'gamma': 0,\n",
    "        'subsample': 1,\n",
    "        'colsample_bytree': 1,\n",
    "        'reg_alpha': 0,\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': args.no_classes,\n",
    "        }\n",
    "    xgb_model = XGBClassifier(**params, use_label_encoder=False)\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    xgb_model.fit(x_train, y_train)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Save the model to local\n",
    "    # ---------------------------------------\n",
    "\n",
    "    temp_name = 'model.bst'\n",
    "    bst = xgb_model.get_booster()\n",
    "    bst.save_model(temp_name)\n",
    "    \n",
    "    # ---------------------------------------\n",
    "    # Move local model to gcs\n",
    "    # ---------------------------------------\n",
    "    \n",
    "    subprocess.check_call(['gsutil', 'cp', temp_name, os.path.join(args.job_dir, 'model.bst')],\n",
    "        stderr=sys.stdout)\n",
    "\n",
    "    return xgb_model\n",
    "\n",
    "def test_xgboost(xgb_model, args):\n",
    "\n",
    "    # Load test data\n",
    "    x_val = pd.read_csv(args.val_feature_name)\n",
    "    y_val = pd.read_csv(args.val_label_name)\n",
    "    \n",
    "    # Perform predictions\n",
    "    pred_val = xgb_model.predict(x_val)\n",
    "    \n",
    "    # One-hot encoding class labels\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_val)\n",
    "    y_val = lb.transform(y_val)\n",
    "    pred_val = lb.transform(pred_val)\n",
    "\n",
    "    # Define the score we want to use to evaluate the classifier on\n",
    "    score = metrics.roc_auc_score(y_val, pred_val, average='macro')\n",
    "    return score\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--job-dir\", type=str, help=\"Required by ai platform training\", default='./')\n",
    "    parser.add_argument(\"--train_feature_name\", type=str, help=\"Path to training feature csv file\")\n",
    "    parser.add_argument(\"--train_label_name\", type=str, help=\"Path to training label csv file\")\n",
    "    parser.add_argument(\"--val_feature_name\", type=str, help=\"Path to validation feature csv file\")\n",
    "    parser.add_argument(\"--val_label_name\", type=str, help=\"Path to validation label csv file\")\n",
    "    parser.add_argument(\"--no_classes\", type=int, help=\"Number of target classes in the label\")\n",
    "    parser.add_argument(\"--n_estimators\", type=int, help=\"Number of estimators in the xgboost model\")\n",
    "    parser.add_argument(\"--max_depth\", type=int, help=\"Maximum depth of trees in xgboost\")\n",
    "    parser.add_argument(\"--booster\", type=str, help=\"Type of booster\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    xgb_model = train_xgboost(args)\n",
    "    score = test_xgboost(xgb_model, args)\n",
    "    \n",
    "    # The default name of the metric is training/hptuning/metric. \n",
    "    # We recommend that you assign a custom name. The only functional difference is that \n",
    "    # if you use a custom name, you must set the hyperparameterMetricTag value in the \n",
    "    # HyperparameterSpec object in your job request to match your chosen name.\n",
    "    # https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#HyperparameterSpec\n",
    "    hpt = hypertune.HyperTune()\n",
    "    hpt.report_hyperparameter_tuning_metric(\n",
    "        metric_value=score,\n",
    "        hyperparameter_metric_tag='roc_auc',\n",
    "        global_step=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure for AI Platform Training\n",
    "Create config file for Cloud AI Platform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./config/config.yaml\n",
    "# python3\n",
    "# ==============================================================================\n",
    "# Copyright 2020 Google LLC. This software is provided as-is, without warranty\n",
    "# or representation for any use or purpose. Your use of it is subject to your\n",
    "# agreement with Google.\n",
    "# ==============================================================================\n",
    "\n",
    "#trainingInput:\n",
    "#  scaleTier: CUSTOM\n",
    "#  masterType: n1-highmem-8\n",
    "#  masterConfig:\n",
    "#    acceleratorConfig:\n",
    "#      count: 1\n",
    "#      type: NVIDIA_TESLA_T4\n",
    "\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure for Hyperparameter Tuning\n",
    "Similarly create config file for Cloud AI Platform Hyperparameter tuning. Moreover, the hyperparameter search space is needed to be configured.\n",
    "\n",
    "The supported hyperparameter types are listed in the job reference documentation. In the ParameterSpec object, you specify the type for each hyperparameter and the related value ranges as described in the following table:\n",
    "\n",
    "|Type        | Value ranges        |Value data            |\n",
    "|------------|---------------------|----------------------|\n",
    "|DOUBLE      |minValue & maxValue  | Floating-point values|\n",
    "|INTEGER     |minValue & maxValue  |Integer values        |\n",
    "|CATEGORICAL |categoricalValues    |List of category strings|\n",
    "|DISCRETE    |discreteValues       |List of values in ascending order|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./config/config_hpt.yaml\n",
    "\n",
    "# python3\n",
    "# ==============================================================================\n",
    "# Copyright 2020 Google LLC. This software is provided as-is, without warranty\n",
    "# or representation for any use or purpose. Your use of it is subject to your\n",
    "# agreement with Google.\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# hptuning_config.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD-1 \n",
    "  hyperparameters:\n",
    "    goal: MAXIMIZE\n",
    "    maxTrials: 5\n",
    "    maxParallelTrials: 5\n",
    "    hyperparameterMetricTag: roc_auc\n",
    "    enableTrialEarlyStopping: TRUE\n",
    "    params:\n",
    "      - parameterName: max_depth\n",
    "        type: INTEGER\n",
    "        minValue: 3\n",
    "        maxValue: 8\n",
    "      - parameterName: n_estimators\n",
    "        type: INTEGER\n",
    "        minValue: 50\n",
    "        maxValue: 200\n",
    "      - parameterName: booster\n",
    "        type: CATEGORICAL\n",
    "        categoricalValues: [\n",
    "          \"gbtree\",\n",
    "          \"gblinear\",\n",
    "          \"dart\"\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
