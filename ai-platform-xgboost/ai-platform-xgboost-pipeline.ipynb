{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Copyright 2020 Google LLC. This software is provided as-is, without warranty\n",
    "# or representation for any use or purpose. Your use of it is subject to your\n",
    "# agreement with Google.\n",
    "# ==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud config list --format 'value(core.project)' 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from datetime import datetime\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'img-seg-3d' # Replace with your project ID\n",
    "USER = 'elvinzhu' # Replace with your User name\n",
    "BUCKET_NAME = 'tuti_asset' # Replace with your bucket name\n",
    "FOLDER_NAME = 'xgb_train_job' # Replace with your Folder name\n",
    "REGION = 'us-central1' # Replace with your region\n",
    "TIMEZONE = 'US/Pacific'\n",
    "\n",
    "JOBNAME = 'xgb_train_{}_{}_hpt'.format(\n",
    "    USER,\n",
    "    datetime.now(timezone(TIMEZONE)).strftime(\"%m%d%y_%H%M\")\n",
    "    )\n",
    "\n",
    "JOB_DIR = 'gs://{}/{}/jobdir'.format(\n",
    "    BUCKET_NAME,\n",
    "    FOLDER_NAME,\n",
    "    )\n",
    "JOB_CONFIG = \"./config/config_hpt.yaml\"\n",
    "print(\"JOB_NAME = \", JOBNAME)\n",
    "print(\"JOB_DIR = \", JOB_DIR)\n",
    "print(\"JOB_CONFIG = \", JOB_CONFIG)\n",
    "\n",
    "TRAIN_FEATURE_PATH = 'gs://tuti_asset/datasets/mortgage_structured_x_train.csv'\n",
    "TRAIN_LABEL_PATH = 'gs://tuti_asset/datasets/mortgage_structured_y_train.csv'\n",
    "VAL_FEATURE_NAME = 'gs://tuti_asset/datasets/mortgage_structured_x_test.csv'\n",
    "VAL_LABEL_NAME = 'gs://tuti_asset/datasets/mortgage_structured_y_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the hyperparameter training job\n",
    "!gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "    --package-path $(pwd)/trainer \\\n",
    "    --module-name trainer.train_hpt \\\n",
    "    --python-version 3.7 \\\n",
    "    --runtime-version 2.2 \\\n",
    "    --job-dir $JOB_DIR \\\n",
    "    --region $REGION \\\n",
    "    --config $JOB_CONFIG \\\n",
    "    -- \\\n",
    "    --train_feature_name $TRAIN_FEATURE_PATH \\\n",
    "    --train_label_name $TRAIN_LABEL_PATH \\\n",
    "    --val_feature_name $VAL_FEATURE_NAME \\\n",
    "    --val_label_name $VAL_LABEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the hyperparameter training job status using gcloud\n",
    "!gcloud ai-platform jobs describe $JOBNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the hyperparameter training job status using googleapiclient\n",
    "\n",
    "from googleapiclient import discovery\n",
    "import json\n",
    "\n",
    "# Define the project id and the job id and format it for the api request\n",
    "job_id = 'projects/{}/jobs/{}'.format(PROJECT_ID, JOBNAME)\n",
    "\n",
    "# Build the service\n",
    "ml = discovery.build('ml', 'v1', cache_discovery=False)\n",
    "# Execute the request and pass in the job id\n",
    "request = ml.projects().jobs().get(name=job_id).execute()\n",
    "\n",
    "# Print response\n",
    "print(json.dumps(request, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trials = request['trainingOutput']['trials']\n",
    "trials = pd.DataFrame(trials)\n",
    "trials['hyperparameters.booster'] = trials['hyperparameters'].apply(lambda x: x['booster'])\n",
    "trials['hyperparameters.max_depth'] = trials['hyperparameters'].apply(lambda x: x['max_depth'])\n",
    "trials['hyperparameters.n_estimators'] = trials['hyperparameters'].apply(lambda x: x['n_estimators'])\n",
    "trials['finalMetric.trainingStep'] = trials['finalMetric'].apply(lambda x: x['trainingStep'])\n",
    "trials['finalMetric.objectiveValue'] = trials['finalMetric'].apply(lambda x: x['objectiveValue'])\n",
    "trials = trials.sort_values(['finalMetric.objectiveValue'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Training with Tuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'img-seg-3d' # Replace with your project ID\n",
    "USER = 'elvinzhu' # Replace with your User name\n",
    "BUCKET_NAME = 'tuti_asset' # Replace with your bucket name\n",
    "FOLDER_NAME = 'xgb_train_job' # Replace with your Folder name\n",
    "REGION = 'us-central1' # Replace with your region\n",
    "TIMEZONE = 'US/Pacific'\n",
    "\n",
    "JOBNAME = 'xgb_train_{}_{}'.format(\n",
    "    USER,\n",
    "    datetime.now(timezone(TIMEZONE)).strftime(\"%m%d%y_%H%M\")\n",
    "    )\n",
    "\n",
    "JOB_DIR = 'gs://{}/{}/{}'.format(\n",
    "    BUCKET_NAME,\n",
    "    FOLDER_NAME,\n",
    "    JOBNAME,\n",
    "    )\n",
    "JOB_CONFIG = \"./config/config.yaml\"\n",
    "\n",
    "print(\"JOB_NAME = \", JOBNAME)\n",
    "print(\"JOB_DIR = \", JOB_DIR)\n",
    "print(\"JOB_CONFIG = \", JOB_CONFIG)\n",
    "\n",
    "# MODEL_PATH = 'models/{}/model.bst'.format(JOBNAME)\n",
    "TRAIN_FEATURE_PATH = 'gs://tuti_asset/datasets/mortgage_structured_x_train.csv'\n",
    "TRAIN_LABEL_PATH = 'gs://tuti_asset/datasets/mortgage_structured_y_train.csv'\n",
    "N_CLASSES = 4\n",
    "\n",
    "print(\"TRAIN_FEATURE_PATH = \", TRAIN_FEATURE_PATH)\n",
    "print(\"TRAIN_LABEL_PATH = \", TRAIN_LABEL_PATH)\n",
    "print(\"N_CLASSES = \", N_CLASSES)\n",
    "\n",
    "# Getthe best hypertuned model parameters\n",
    "BOOSTER=trials['hyperparameters'][0]['booster']\n",
    "MAX_DEPTH=trials['hyperparameters'][0]['max_depth']\n",
    "N_ESTIMATORS=trials['hyperparameters'][0]['n_estimators']\n",
    "\n",
    "print(\"BOOSTER = \", BOOSTER)\n",
    "print(\"MAX_DEPTH = \", MAX_DEPTH)\n",
    "print(\"N_ESTIMATORS = \", N_ESTIMATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on local machine\n",
    "!python3 trainer/train.py \\\n",
    "    --train_feature_name $TRAIN_FEATURE_PATH \\\n",
    "    --train_label_name $TRAIN_LABEL_PATH \\\n",
    "    --no_classes $N_CLASSES \\\n",
    "    --n_estimators $N_ESTIMATORS \\\n",
    "    --max_depth $MAX_DEPTH \\\n",
    "    --booster $BOOSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud ai-platform local train \\\n",
    "    --job-dir $JOB_DIR \\\n",
    "    --package-path $(pwd)/trainer \\\n",
    "    --module-name trainer.train \\\n",
    "    -- \\\n",
    "    --train_feature_name $TRAIN_FEATURE_PATH \\\n",
    "    --train_label_name $TRAIN_LABEL_PATH \\\n",
    "    --no_classes $N_CLASSES \\\n",
    "    --n_estimators $N_ESTIMATORS \\\n",
    "    --max_depth $MAX_DEPTH \\\n",
    "    --booster $BOOSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training\n",
    "\n",
    "# submit the training job\n",
    "! gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "    --job-dir $JOB_DIR \\\n",
    "    --package-path $(pwd)/trainer \\\n",
    "    --module-name trainer.train \\\n",
    "    --region $REGION \\\n",
    "    --python-version 3.7 \\\n",
    "    --runtime-version 2.2 \\\n",
    "    --config $JOB_CONFIG \\\n",
    "    -- \\\n",
    "    --train_feature_name $TRAIN_FEATURE_PATH \\\n",
    "    --train_label_name $TRAIN_LABEL_PATH \\\n",
    "    --no_classes $N_CLASSES \\\n",
    "    --n_estimators $N_ESTIMATORS \\\n",
    "    --max_depth $MAX_DEPTH \\\n",
    "    --booster $BOOSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the training job status\n",
    "! gcloud ai-platform jobs describe $JOBNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "# Deploy the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xgb_model\"\n",
    "MODEL_VERSION = \"elvinzhu_xgb_bst_v0_1\"\n",
    "REGION = \"global\"\n",
    "MODEL_FRAMEWORK = \"XGBOOST\"\n",
    "MODEL_DESCRIPTION = \"best_xgb_hpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all models in region\n",
    "!gcloud ai-platform models list --region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model if not exist\n",
    "!gcloud ai-platform models create $MODEL_NAME --region $REGION --enable-logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list model versions under model\n",
    "!gcloud ai-platform versions list --model $MODEL_NAME --region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATEST_MODEL_DIR = \"gs://{}/{}/{}\".format(BUCKET_NAME, FOLDER_NAME, JOBNAME)\n",
    "print(\"LATEST_MODEL_DIR: \", LATEST_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a list of model directories\n",
    "# ALL_MODEL_DIRS = ! gsutil ls $MODEL_DIR\n",
    "# # Pick the directory with the latest timestamp, in case you have trained multiple times\n",
    "# if (\"CommandException\" in ALL_MODEL_DIRS[0]):\n",
    "#     print(\"Create the model directory first\")\n",
    "# else:\n",
    "#     LATEST_MODEL_DIR = ALL_MODEL_DIRS[-1]\n",
    "# print(\"Latest Model Directory = \", LATEST_MODEL_DIR)\n",
    "\n",
    "# Deploy the model\n",
    "! gcloud beta ai-platform versions create $MODEL_VERSION \\\n",
    "  --model=$MODEL_NAME \\\n",
    "  --origin=$LATEST_MODEL_DIR \\\n",
    "  --runtime-version=2.2 \\\n",
    "  --python-version=3.7 \\\n",
    "  --framework=$MODEL_FRAMEWORK \\\n",
    "  --description=$MODEL_DESCRIPTION \\\n",
    "  --region=$REGION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all models\n",
    "!gcloud ai-platform models list --region $REGION\n",
    "# List all versions of the created model\n",
    "!gcloud ai-platform versions list --model $MODEL_NAME --region $REGION\n",
    "# Describe the Model\n",
    "!gcloud ai-platform models describe $MODEL_NAME --region $REGION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Predictions from the deployed model with test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test feature and labels\n",
    "test_feature_url = 'gs://tuti_asset/datasets/mortgage_structured_x_test.csv'\n",
    "test_label_url = 'gs://tuti_asset/datasets/mortgage_structured_y_test.csv'\n",
    "\n",
    "x_test = pd.read_csv(test_feature_url)\n",
    "y_test = pd.read_csv(test_label_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Google API for online prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create google API client \n",
    "import googleapiclient.discovery\n",
    "import numpy as np\n",
    "\n",
    "PROJECT_ID = \"img-seg-3d\"\n",
    "MODEL_NAME = \"xgb_model\"\n",
    "VERSION = \"elvinzhu_xgb_bst\"\n",
    "prediction_file = './prediction.json'\n",
    "batch_size = 1000\n",
    "\n",
    "model_name = 'projects/{}/models/{}/versions/{}'.format(\n",
    "    PROJECT_ID, \n",
    "    MODEL_NAME, \n",
    "    VERSION\n",
    "    )\n",
    "\n",
    "service = googleapiclient.discovery.build(\n",
    "    'ml', \n",
    "    'v1', \n",
    "    cache_discovery=False, \n",
    "    cache=False\n",
    "    )\n",
    "\n",
    "prediction_list = []\n",
    "\n",
    "for ind in range(0, len(x_test), batch_size):\n",
    "    start = ind\n",
    "    end = min(ind+batch_size, len(x_test))\n",
    "    response = service.projects().predict(\n",
    "        name=model_name,\n",
    "        body={'instances': x_test.iloc[start:end].values.tolist()}\n",
    "        ).execute()\n",
    "    prediction_list += response['predictions']\n",
    "    \n",
    "prediction_list = np.array(prediction_list)\n",
    "preds = np.argmax(prediction_list, axis=1)\n",
    "print(\"Predict array size = \", np.array(preds).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other way to call Cloud AI Platform API using gcloud command for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body={'instances': x_test.iloc[0:1000].values.tolist()}\n",
    "with open('xgb_test_data.json', 'w') as fp:\n",
    "    json.dump(body, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predict_results = !gcloud ai-platform predict \\\n",
    "  --model=$MODEL_NAME \\\n",
    "  --version=$MODEL_VERSION \\\n",
    "  --format='text' \\\n",
    "  --json-request='xgb_test_data.json' \\\n",
    "  --region='global'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
