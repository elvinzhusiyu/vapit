{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ============================================================================== \\\n",
    " Copyright 2020 Google LLC. This software is provided as-is, without warranty \\\n",
    " or representation for any use or purpose. Your use of it is subject to your \\\n",
    " agreement with Google. \\\n",
    " ============================================================================== \n",
    " \n",
    " Author: Elvin Zhu, Chanchal Chatterjee \\\n",
    " Email: elvinzhu@google.com \\\n",
    "<img src=\"img/google-cloud-icon.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List your current GCP project name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img-seg-3d\n"
     ]
    }
   ],
   "source": [
    "!gcloud config list --format 'value(core.project)' 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from googleapiclient import discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### Dataset preprocessing\n",
    "\n",
    "Preprocess input data by\n",
    "\n",
    "    1. Dropping unique ID column;\n",
    "    2. Convert categorical into one-hot encodings;\n",
    "    3. Count number of unique classes;\n",
    "    4. Split train/test\n",
    "    5. Save process data into gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Preprocessing raw data:\n",
      "INFO:root: => Drop id column:\n",
      "INFO:root: => One hot encoding categorical features\n",
      "INFO:root: => Count number of classes\n",
      "INFO:root: => Perform train/test split\n",
      "INFO:root:Reading raw data file: gs://tuti_asset/datasets/mortgage_structured.csv\n",
      "INFO:root:Drop unique id column which is not an useful feature for ML: LOAN_SEQUENCE_NUMBER\n",
      "INFO:root:Convert categorical columns into one-hot encodings\n",
      "INFO:root:categorical feature: first_time_home_buyer_flag\n",
      "INFO:root:categorical feature: occupancy_status\n",
      "INFO:root:categorical feature: channel\n",
      "INFO:root:categorical feature: property_state\n",
      "INFO:root:categorical feature: property_type\n",
      "INFO:root:categorical feature: loan_purpose\n",
      "INFO:root:categorical feature: seller_name\n",
      "INFO:root:categorical feature: service_name\n",
      "INFO:root:Count number of unique classes ...\n",
      "INFO:root:No. of Classes: 4\n",
      "INFO:root:Perform train/test split ...\n",
      "INFO:root:Get feature/label shapes ...\n",
      "INFO:root:x_train shape = (93639, 149)\n",
      "INFO:root:x_test shape = (10405, 149)\n",
      "INFO:root:y_train shape = (93639,)\n",
      "INFO:root:y_test shape = (10405,)\n",
      "INFO:root:Saving data ...\n",
      "INFO:root:x_train saved to gs://tuti_job/data_split/mortgage_structured_x_train.csv\n",
      "INFO:root:x_test saved to gs://tuti_job/data_split/mortgage_structured_x_test.csv\n",
      "INFO:root:y_train saved to gs://tuti_job/data_split/mortgage_structured_y_train.csv\n",
      "INFO:root:y_test saved to gs://tuti_job/data_split/mortgage_structured_y_test.csv\n",
      "INFO:root:finished\n"
     ]
    }
   ],
   "source": [
    "INPUT_DATA = \"gs://tuti_asset/datasets/mortgage_structured.csv\" # public mortgage data \n",
    "TARGET_COLUMN = \"TARGET\" # Column name for target labels\n",
    "\n",
    "# TODO: Update gcs path before proceeding\n",
    "TRAIN_FEATURE_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_x_train.csv\" # Update with your gcs path\n",
    "TRAIN_LABEL_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_y_train.csv\" # Update with your gcs path\n",
    "TEST_FEATURE_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_x_test.csv\" # Update with your gcs path\n",
    "TEST_LABEL_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_y_test.csv\" # Update with your gcs path\n",
    "\n",
    "!python3 preprocessing.py \\\n",
    "    --input_file $INPUT_DATA \\\n",
    "    --x_train_name $TRAIN_FEATURE_PATH \\\n",
    "    --x_test_name $TEST_FEATURE_PATH \\\n",
    "    --y_train_name $TRAIN_LABEL_PATH \\\n",
    "    --y_test_name $TEST_LABEL_PATH \\\n",
    "    --target_column $TARGET_COLUMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Training with Google AI Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the full article, please visit: https://cloud.google.com/ai-platform/docs/technical-overview\n",
    "\n",
    "Where AI Platform fits in the ML workflow \\\n",
    "The diagram below gives a high-level overview of the stages in an ML workflow. The blue-filled boxes indicate where AI Platform provides managed services and APIs:\n",
    "\n",
    "<img src=\"img/ml-workflow.svg\" alt=\"Drawing\">\n",
    "\n",
    "As the diagram indicates, you can use AI Platform to manage the following stages in the ML workflow:\n",
    "\n",
    "- Train an ML model on your data:\n",
    " - Train model\n",
    " - Evaluate model accuracy\n",
    " - Tune hyperparameters\n",
    " \n",
    " \n",
    "- Deploy your trained model.\n",
    "\n",
    "- Send prediction requests to your model:\n",
    " - Online prediction\n",
    " - Batch prediction (for TensorFlow only)\n",
    " \n",
    " \n",
    "- Monitor the predictions on an ongoing basis.\n",
    "\n",
    "\n",
    "- Manage your models and model versions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_NAME =  xgb_train_elvinzhu_051021_1159\n",
      "JOB_DIR =  gs://tuti_asset/xgb_train_job/xgb_train_elvinzhu_051021_1159\n",
      "JOB_CONFIG =  ./config/config.yaml\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = '<YOUR-PROJECT>'     # Replace with your project ID\n",
    "USER = '<YOUR-USERNAME>'             # Replace with your user name\n",
    "BUCKET_NAME = '<YOUR-BUCKET>'    # Replace with your gcs bucket name\n",
    "FOLDER_NAME = 'xgb_train_job' # Replace with your gcs folder name\n",
    "REGION = 'us-central1'        # Replace with your GCP region\n",
    "TIMEZONE = 'US/Pacific'       # Replace with your local timezone\n",
    "\n",
    "# Google Cloud AI Platform requires each job to have unique name, \n",
    "# Therefore, we use prefix + timestamp to form job names.\n",
    "JOBNAME = 'xgb_train_{}_{}'.format(\n",
    "    USER,\n",
    "    datetime.now(timezone(TIMEZONE)).strftime(\"%m%d%y_%H%M\")\n",
    "    ) # Unique job name\n",
    "\n",
    "# We use the job names as folder names to store outputs.\n",
    "JOB_DIR = 'gs://{}/{}/{}'.format(\n",
    "    BUCKET_NAME,\n",
    "    FOLDER_NAME,\n",
    "    JOBNAME,\n",
    "    ) # gcs path to hold the outputs\n",
    "\n",
    "# This is the AI Platform configuration for training, created in the setup step\n",
    "JOB_CONFIG = \"./config/config.yaml\" # local path to training config file\n",
    "\n",
    "# TODO: Update gcs path before proceeding\n",
    "TRAIN_FEATURE_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_x_train.csv\" # Update with your gcs path\n",
    "TRAIN_LABEL_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_y_train.csv\" # Update with your gcs path\n",
    "\n",
    "# Get the initial set of hyperparameters\n",
    "N_CLASSES = 4 \n",
    "BOOSTER = 'gbtree' # Booster type\n",
    "MAX_DEPTH = 2      # Depth of trees\n",
    "N_ESTIMATORS = 10  # No of estimators\n",
    "\n",
    "print(\"JOB_NAME = \", JOBNAME)\n",
    "print(\"JOB_DIR = \", JOB_DIR)\n",
    "print(\"JOB_CONFIG = \", JOB_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train at local\n",
    "\n",
    "Before submitting training jobs to Cloud AI Platform, you can test your train.py code in the local environment. You can test by running your python script in command line, but another and maybe better choice is to use `gcloud ai-platform local train` command. The latter method could make sure your your entire python package are ready to be submitted to the remote VMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:59:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Copying file://./model.bst...\n",
      "/ [1 files][ 16.2 KiB/ 16.2 KiB]                                                \n",
      "Operation completed over 1 objects/16.2 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# Train on local machine with python command\n",
    "!python3 trainer/train.py \\\n",
    "    --job-dir ./models \\\n",
    "    --train_feature_name $TRAIN_FEATURE_PATH \\\n",
    "    --train_label_name $TRAIN_LABEL_PATH \\\n",
    "    --no_classes $N_CLASSES \\\n",
    "    --n_estimators $N_ESTIMATORS \\\n",
    "    --max_depth $MAX_DEPTH \\\n",
    "    --booster $BOOSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:00:18] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Copying file://./model.bst...\n",
      "/ [1 files][ 16.2 KiB/ 16.2 KiB]                                                \n",
      "Operation completed over 1 objects/16.2 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# Train on local machine with gcloud command\n",
    "!gcloud ai-platform local train \\\n",
    "    --job-dir ./models \\\n",
    "    --package-path $(pwd)/trainer \\\n",
    "    --module-name trainer.train \\\n",
    "    -- \\\n",
    "    --train_feature_name $TRAIN_FEATURE_PATH \\\n",
    "    --train_label_name $TRAIN_LABEL_PATH \\\n",
    "    --no_classes $N_CLASSES \\\n",
    "    --n_estimators $N_ESTIMATORS \\\n",
    "    --max_depth $MAX_DEPTH \\\n",
    "    --booster $BOOSTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit jobs to AI platform\n",
    "See link for a full list of arguments: \\\n",
    "https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [xgb_train_elvinzhu_051021_1159] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe xgb_train_elvinzhu_051021_1159\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs xgb_train_elvinzhu_051021_1159\n",
      "jobId: xgb_train_elvinzhu_051021_1159\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "# submit the training job to AI Platform\n",
    "! gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "    --job-dir $JOB_DIR \\\n",
    "    --package-path $(pwd)/trainer \\\n",
    "    --module-name trainer.train \\\n",
    "    --region $REGION \\\n",
    "    --python-version 3.7 \\\n",
    "    --runtime-version 2.2 \\\n",
    "    --config $JOB_CONFIG \\\n",
    "    -- \\\n",
    "    --train_feature_name $TRAIN_FEATURE_PATH \\\n",
    "    --train_label_name $TRAIN_LABEL_PATH \\\n",
    "    --no_classes $N_CLASSES \\\n",
    "    --n_estimators $N_ESTIMATORS \\\n",
    "    --max_depth $MAX_DEPTH \\\n",
    "    --booster $BOOSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2021-05-10T19:00:35Z'\n",
      "etag: OXFLlbxrIYo=\n",
      "jobId: xgb_train_elvinzhu_051021_1159\n",
      "state: PREPARING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --train_feature_name\n",
      "  - gs://tuti_job/data_split/mortgage_structured_x_train.csv\n",
      "  - --train_label_name\n",
      "  - gs://tuti_job/data_split/mortgage_structured_y_train.csv\n",
      "  - --no_classes\n",
      "  - '4'\n",
      "  - --n_estimators\n",
      "  - '10'\n",
      "  - --max_depth\n",
      "  - '2'\n",
      "  - --booster\n",
      "  - gbtree\n",
      "  jobDir: gs://tuti_asset/xgb_train_job/xgb_train_elvinzhu_051021_1159\n",
      "  packageUris:\n",
      "  - gs://tuti_asset/xgb_train_job/xgb_train_elvinzhu_051021_1159/packages/92751de3631a2bdb011a6f9d31979ad12d914688a340028c97bdc62299b8774f/trainer-0.1.tar.gz\n",
      "  pythonModule: trainer.train\n",
      "  pythonVersion: '3.7'\n",
      "  region: us-central1\n",
      "  runtimeVersion: '2.2'\n",
      "  scaleTier: STANDARD_1\n",
      "trainingOutput: {}\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/mlengine/jobs/xgb_train_elvinzhu_051021_1159?project=img-seg-3d\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2Fxgb_train_elvinzhu_051021_1159&project=img-seg-3d\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs describe $JOBNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "To use hyperparameter tuning in your training job you must perform the following steps:\n",
    "\n",
    "- Specify the hyperparameter tuning configuration for your training job by including a HyperparameterSpec in your TrainingInput object.\n",
    "\n",
    "- Include the following code in your training application:\n",
    "\n",
    " - Parse the command-line arguments representing the hyperparameters you want to tune, and use the values to set the hyperparameters for your training trial.\n",
    " - Add your hyperparameter metric to the summary for your graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_NAME =  xgb_train_elvinzhu_051021_1200_hpt\n",
      "JOB_DIR =  gs://tuti_asset/xgb_train_job/jobdir\n",
      "JOB_CONFIG =  ./config/config_hpt.yaml\n"
     ]
    }
   ],
   "source": [
    "# Gcloud training config\n",
    "PROJECT_ID = '<YOUR-PROJECT>'     # Replace with your project ID\n",
    "USER = '<YOUR-USERNAME>'             # Replace with your user name\n",
    "BUCKET_NAME = '<YOUR-BUCKET>'    # Replace with your gcs bucket name\n",
    "FOLDER_NAME = 'xgb_train_job' # Replace with your gcs folder name\n",
    "REGION = 'us-central1'        # Replace with your GCP region\n",
    "TIMEZONE = 'US/Pacific'       # Replace with your local timezone\n",
    "\n",
    "# Google Cloud AI Platform requires each job to have unique name, \n",
    "# Therefore, we use prefix + timestamp to form job names.\n",
    "JOBNAME = 'xgb_train_{}_{}_hpt'.format(\n",
    "    USER,\n",
    "    datetime.now(timezone(TIMEZONE)).strftime(\"%m%d%y_%H%M\")\n",
    "    ) # define unique job name\n",
    "\n",
    "# We use the job names as folder names to store outputs.\n",
    "JOB_DIR = 'gs://{}/{}/jobdir'.format(\n",
    "    BUCKET_NAME,\n",
    "    FOLDER_NAME,\n",
    "    ) # define unique job dir on gcs\n",
    "\n",
    "# This is the AI Platform configuration for hypertune, created in the setup step\n",
    "JOB_CONFIG = \"./config/config_hpt.yaml\" # local path to hypertune config file\n",
    "\n",
    "# TODO: Update gcs path before proceeding\n",
    "TRAIN_FEATURE_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_x_train.csv\" # Update with your gcs path\n",
    "TRAIN_LABEL_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_y_train.csv\" # Update with your gcs path\n",
    "TEST_FEATURE_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_x_test.csv\" # Update with your gcs path\n",
    "TEST_LABEL_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_y_test.csv\" # Update with your gcs path\n",
    "\n",
    "print(\"JOB_NAME = \", JOBNAME)\n",
    "print(\"JOB_DIR = \", JOB_DIR)\n",
    "print(\"JOB_CONFIG = \", JOB_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [xgb_train_elvinzhu_051021_1200_hpt] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe xgb_train_elvinzhu_051021_1200_hpt\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs xgb_train_elvinzhu_051021_1200_hpt\n",
      "jobId: xgb_train_elvinzhu_051021_1200_hpt\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "# submit the hyperparameter training job\n",
    "!gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "    --package-path $(pwd)/trainer \\\n",
    "    --module-name trainer.train_hpt \\\n",
    "    --python-version 3.7 \\\n",
    "    --runtime-version 2.2 \\\n",
    "    --job-dir $JOB_DIR \\\n",
    "    --region $REGION \\\n",
    "    --config $JOB_CONFIG \\\n",
    "    -- \\\n",
    "    --train_feature_name $TRAIN_FEATURE_PATH \\\n",
    "    --train_label_name $TRAIN_LABEL_PATH \\\n",
    "    --val_feature_name $TEST_FEATURE_PATH \\\n",
    "    --val_label_name $TEST_LABEL_PATH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the status of Long Running Operation (LRO) a.k.a. jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2021-05-10T19:00:49Z'\n",
      "etag: J9hzRs89s4M=\n",
      "jobId: xgb_train_elvinzhu_051021_1200_hpt\n",
      "startTime: '2021-05-10T19:00:51Z'\n",
      "state: RUNNING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --train_feature_name\n",
      "  - gs://tuti_job/data_split/mortgage_structured_x_train.csv\n",
      "  - --train_label_name\n",
      "  - gs://tuti_job/data_split/mortgage_structured_y_train.csv\n",
      "  - --val_feature_name\n",
      "  - gs://tuti_job/data_split/mortgage_structured_x_test.csv\n",
      "  - --val_label_name\n",
      "  - gs://tuti_job/data_split/mortgage_structured_y_test.csv\n",
      "  hyperparameters:\n",
      "    enableTrialEarlyStopping: true\n",
      "    goal: MAXIMIZE\n",
      "    hyperparameterMetricTag: roc_auc\n",
      "    maxParallelTrials: 5\n",
      "    maxTrials: 10\n",
      "    params:\n",
      "    - maxValue: 20.0\n",
      "      minValue: 2.0\n",
      "      parameterName: max_depth\n",
      "      type: INTEGER\n",
      "    - maxValue: 200.0\n",
      "      minValue: 10.0\n",
      "      parameterName: n_estimators\n",
      "      type: INTEGER\n",
      "    - categoricalValues:\n",
      "      - gbtree\n",
      "      - gblinear\n",
      "      - dart\n",
      "      parameterName: booster\n",
      "      type: CATEGORICAL\n",
      "  jobDir: gs://tuti_asset/xgb_train_job/jobdir\n",
      "  packageUris:\n",
      "  - gs://tuti_asset/xgb_train_job/jobdir/packages/9471462a259d85ad0b2a18cb6821258efb3047636f523ea617fff962ad5bcf27/trainer-0.1.tar.gz\n",
      "  pythonModule: trainer.train_hpt\n",
      "  pythonVersion: '3.7'\n",
      "  region: us-central1\n",
      "  runtimeVersion: '2.2'\n",
      "  scaleTier: STANDARD_1\n",
      "trainingOutput:\n",
      "  hyperparameterMetricTag: roc_auc\n",
      "  isHyperparameterTuningJob: true\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/mlengine/jobs/xgb_train_elvinzhu_051021_1200_hpt?project=img-seg-3d\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2Fxgb_train_elvinzhu_051021_1200_hpt&project=img-seg-3d\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs describe $JOBNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the status of Long Running Operation (LRO) with Google API Client\n",
    "\n",
    "Send an API request to Cloud AI Platform to get the detailed information. The most interesting piece of information is the hyperparameter values in the trial with best performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the project id and the job id and format it for the api request\n",
    "# We need to use project id and job name from last step\n",
    "job_id = 'projects/{}/jobs/{}'.format(PROJECT_ID, JOBNAME)\n",
    "# Build the service\n",
    "ml = discovery.build('ml', 'v1', cache_discovery=False)\n",
    "# Execute the request and pass in the job id\n",
    "request = ml.projects().jobs().get(name=job_id).execute()\n",
    "# Print response\n",
    "logging.info(json.dumps(request, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse request response and sort experiments based on final metrics\n",
    "trials = request['trainingOutput']['trials']\n",
    "trials = pd.DataFrame(trials)\n",
    "trials['hyperparameters.booster'] = trials['hyperparameters'].apply(lambda x: x['booster'])\n",
    "trials['hyperparameters.max_depth'] = trials['hyperparameters'].apply(lambda x: x['max_depth'])\n",
    "trials['hyperparameters.n_estimators'] = trials['hyperparameters'].apply(lambda x: x['n_estimators'])\n",
    "trials['finalMetric.trainingStep'] = trials['finalMetric'].apply(lambda x: x['trainingStep'])\n",
    "trials['finalMetric.objectiveValue'] = trials['finalMetric'].apply(lambda x: x['objectiveValue'])\n",
    "trials = trials.sort_values(['finalMetric.objectiveValue'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Training with Tuned Parameters\n",
    "\n",
    "Once your hyperparameter training jobs are done. You can use the optimized combination of hyperparameters from your trials and start a single training job on Cloud AI Platform to train your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_NAME =  xgb_train_elvinzhu_051021_1127\n",
      "JOB_DIR =  gs://tuti_asset/xgb_train_job/xgb_train_elvinzhu_051021_1127\n",
      "JOB_CONFIG =  ./config/config.yaml\n",
      "TRAIN_FEATURE_PATH =  gs://tuti_job/data_split/mortgage_structured_x_train.csv\n",
      "TRAIN_LABEL_PATH =  gs://tuti_job/data_split/mortgage_structured_y_train.csv\n",
      "N_CLASSES =  4\n",
      "BOOSTER =  gbtree\n",
      "MAX_DEPTH =  14\n",
      "N_ESTIMATORS =  40\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = '<YOUR-PROJECT>' # Replace with your project ID\n",
    "USER = '<YOUR-USERNAME>' # Replace with your User name\n",
    "BUCKET_NAME = '<YOUR-BUCKET>' # Replace with your bucket name\n",
    "FOLDER_NAME = 'xgb_train_job' # Replace with your Folder name\n",
    "REGION = 'us-central1' # Replace with your region\n",
    "TIMEZONE = 'US/Pacific'\n",
    "\n",
    "# Google Cloud AI Platform requires each job to have unique name, \n",
    "# Therefore, we use prefix + timestamp to form job names.\n",
    "JOBNAME = 'xgb_train_{}_{}'.format(\n",
    "    USER,\n",
    "    datetime.now(timezone(TIMEZONE)).strftime(\"%m%d%y_%H%M\")\n",
    "    )\n",
    "# We use the job names as folder names to store outputs.\n",
    "JOB_DIR = 'gs://{}/{}/{}'.format(\n",
    "    BUCKET_NAME,\n",
    "    FOLDER_NAME,\n",
    "    JOBNAME,\n",
    "    )\n",
    "\n",
    "# This is the AI Platform configuration for training, created in the setup step\n",
    "JOB_CONFIG = \"./config/config.yaml\" # local path to train config file\n",
    "\n",
    "print(\"JOB_NAME = \", JOBNAME)\n",
    "print(\"JOB_DIR = \", JOB_DIR)\n",
    "print(\"JOB_CONFIG = \", JOB_CONFIG)\n",
    "\n",
    "# TODO: Update gcs path before proceeding\n",
    "TRAIN_FEATURE_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_x_train.csv\" # Update with your gcs path\n",
    "TRAIN_LABEL_PATH = \"gs://<YOUR-BUCKET>/data_split/mortgage_structured_y_train.csv\" # Update with your gcs path\n",
    "\n",
    "# Getthe best hypertuned model parameters\n",
    "N_CLASSES = 4\n",
    "BOOSTER=trials['hyperparameters'][0]['booster']\n",
    "MAX_DEPTH=trials['hyperparameters'][0]['max_depth']\n",
    "N_ESTIMATORS=trials['hyperparameters'][0]['n_estimators']\n",
    "\n",
    "print(\"TRAIN_FEATURE_PATH = \", TRAIN_FEATURE_PATH)\n",
    "print(\"TRAIN_LABEL_PATH = \", TRAIN_LABEL_PATH)\n",
    "print(\"N_CLASSES = \", N_CLASSES)\n",
    "print(\"BOOSTER = \", BOOSTER)\n",
    "print(\"MAX_DEPTH = \", MAX_DEPTH)\n",
    "print(\"N_ESTIMATORS = \", N_ESTIMATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [xgb_train_elvinzhu_051021_1127] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe xgb_train_elvinzhu_051021_1127\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs xgb_train_elvinzhu_051021_1127\n",
      "jobId: xgb_train_elvinzhu_051021_1127\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "# submit the training job\n",
    "! gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "    --job-dir $JOB_DIR \\\n",
    "    --package-path $(pwd)/trainer \\\n",
    "    --module-name trainer.train \\\n",
    "    --region $REGION \\\n",
    "    --python-version 3.7 \\\n",
    "    --runtime-version 2.2 \\\n",
    "    --config $JOB_CONFIG \\\n",
    "    -- \\\n",
    "    --train_feature_name $TRAIN_FEATURE_PATH \\\n",
    "    --train_label_name $TRAIN_LABEL_PATH \\\n",
    "    --no_classes $N_CLASSES \\\n",
    "    --n_estimators $N_ESTIMATORS \\\n",
    "    --max_depth $MAX_DEPTH \\\n",
    "    --booster $BOOSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2021-05-10T18:28:01Z'\n",
      "etag: Dg4mDeqQav4=\n",
      "jobId: xgb_train_elvinzhu_051021_1127\n",
      "state: PREPARING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --train_feature_name\n",
      "  - gs://tuti_job/data_split/mortgage_structured_x_train.csv\n",
      "  - --train_label_name\n",
      "  - gs://tuti_job/data_split/mortgage_structured_y_train.csv\n",
      "  - --no_classes\n",
      "  - '4'\n",
      "  - --n_estimators\n",
      "  - '40'\n",
      "  - --max_depth\n",
      "  - '14'\n",
      "  - --booster\n",
      "  - gbtree\n",
      "  jobDir: gs://tuti_asset/xgb_train_job/xgb_train_elvinzhu_051021_1127\n",
      "  packageUris:\n",
      "  - gs://tuti_asset/xgb_train_job/xgb_train_elvinzhu_051021_1127/packages/4d6b22c6e0465194179718d43655fd50229da70cdc29ab65a4acdd5ede64da2a/trainer-0.1.tar.gz\n",
      "  pythonModule: trainer.train\n",
      "  pythonVersion: '3.7'\n",
      "  region: us-central1\n",
      "  runtimeVersion: '2.2'\n",
      "  scaleTier: STANDARD_1\n",
      "trainingOutput: {}\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/mlengine/jobs/xgb_train_elvinzhu_051021_1127?project=img-seg-3d\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2Fxgb_train_elvinzhu_051021_1127&project=img-seg-3d\n"
     ]
    }
   ],
   "source": [
    "# check the training job status\n",
    "! gcloud ai-platform jobs describe $JOBNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### Deploy the Model\n",
    "\n",
    "AI Platform provides tools to upload your trained ML model to the cloud, so that you can send prediction requests to the model.\n",
    "\n",
    "In order to deploy your trained model on AI Platform, you must save your trained model using the tools provided by your machine learning framework. This involves serializing the information that represents your trained model into a file which you can deploy for prediction in the cloud.\n",
    "\n",
    "Then you upload the saved model to a Cloud Storage bucket, and create a model resource on AI Platform, specifying the Cloud Storage path to your saved model.\n",
    "\n",
    "When you deploy your model, you can also provide custom code (beta) to customize how it handles prediction requests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xgb_model\"                # Model name of your choice to deploy\n",
    "MODEL_VERSION = \"xgb_bst_v0_1\" # Model version name of your choice to deploy\n",
    "REGION = \"global\"                       # The deployed model region\n",
    "MODEL_FRAMEWORK = \"XGBOOST\"             # The deployed model framework (tensorflow, sklearn, xgboost)\n",
    "MODEL_DESCRIPTION = \"best_xgb_hpt\"      # The description of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model if not exist\n",
    "!gcloud ai-platform models create $MODEL_NAME --region $\"global\" --enable-logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list model versions under model\n",
    "!gcloud ai-platform versions list --model $MODEL_NAME --region \"global\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gcs path contains your latested trained model\n",
    "LATEST_MODEL_DIR = \"gs://{}/{}/{}\".format(BUCKET_NAME, FOLDER_NAME, JOBNAME)\n",
    "print(\"LATEST_MODEL_DIR: \", LATEST_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model to endpoint\n",
    "! gcloud beta ai-platform versions create $MODEL_VERSION \\\n",
    "  --model=$MODEL_NAME \\\n",
    "  --origin=$LATEST_MODEL_DIR \\\n",
    "  --runtime-version=2.2 \\\n",
    "  --python-version=3.7 \\\n",
    "  --framework=$MODEL_FRAMEWORK \\\n",
    "  --description=$MODEL_DESCRIPTION \\\n",
    "  --region=$REGION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all models\n",
    "!gcloud ai-platform models list --region $REGION\n",
    "# List all versions of the created model\n",
    "!gcloud ai-platform versions list --model $MODEL_NAME --region $REGION\n",
    "# Describe the Model\n",
    "!gcloud ai-platform models describe $MODEL_NAME --region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Send inference requests to your model\n",
    "\n",
    "AI Platform provides the services you need to request predictions from your model in the cloud.\n",
    "\n",
    "There are two ways to get predictions from trained models: online prediction (sometimes called HTTP prediction) and batch prediction. In both cases, you pass input data to a cloud-hosted machine-learning model and get inferences for each data instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test feature and labels\n",
    "# TODO: Update gcs path before proceeding\n",
    "test_feature_url = \"gs://<your bucket name>/<your folder name>/mortgage_structured_x_test.csv\" # Update with your gcs path\n",
    "test_label_url = \"gs://<your bucket name>/<your folder name>/mortgage_structured_y_test.csv\" # Update with your gcs path\n",
    "\n",
    "x_test = pd.read_csv(test_feature_url)\n",
    "y_test = pd.read_csv(test_label_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Google API for online inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create google API client \n",
    "PROJECT_ID = \"<YOUR-PROJECT>\" # Your project id\n",
    "MODEL_NAME = \"xgb_model\"  # The model name from previous step\n",
    "VERSION = \"xgb_bst_v0_1\" # The model version from previous step\n",
    "batch_size = 1000\n",
    "\n",
    "# Create model inference with Google API Client \n",
    "# Model endpoint name\n",
    "model_name = 'projects/{}/models/{}/versions/{}'.format(\n",
    "    PROJECT_ID, \n",
    "    MODEL_NAME, \n",
    "    VERSION\n",
    "    )\n",
    "\n",
    "# Build the service\n",
    "service = googleapiclient.discovery.build(\n",
    "    'ml', \n",
    "    'v1', \n",
    "    cache_discovery=False, \n",
    "    cache=False\n",
    "    )\n",
    "\n",
    "prediction_list = []\n",
    "\n",
    "for ind in range(0, len(x_test), batch_size):\n",
    "    start = ind\n",
    "    end = min(ind+batch_size, len(x_test))\n",
    "    response = service.projects().predict(\n",
    "        name=model_name,\n",
    "        body={'instances': x_test.iloc[start:end].values.tolist()}\n",
    "        ).execute()\n",
    "    prediction_list += response['predictions']\n",
    "    \n",
    "prediction_list = np.array(prediction_list)\n",
    "preds = np.argmax(prediction_list, axis=1)\n",
    "print(\"Predict array size = \", np.array(preds).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other way to call Cloud AI Platform API using gcloud command for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(predict, n_sample, n_class):  \n",
    "    \"\"\"Parse response of inference requests,\n",
    "    Args:\n",
    "        predict: List of strings, inference request response;\n",
    "        n_sample: No. of samples for inference;\n",
    "        n_class: No. of classes\n",
    "    Return:\n",
    "        List of inference labels\n",
    "    \"\"\"\n",
    "    predictions = np.empty([n_sample, n_class])\n",
    "    for entry in predict[1:]:\n",
    "        key, value = entry.split(\":\")\n",
    "        exec(\"{} = {}\".format(key, value))\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return predictions.tolist()\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\" Compute accuracy score\n",
    "    Args:\n",
    "        y_ture: list of ground truth labels,\n",
    "        y_pred: list of predicted labels,\n",
    "    Return:\n",
    "        float, accuracy score\n",
    "    \"\"\"\n",
    "    from sklearn import metrics\n",
    "    return metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"<YOUR-PROJECT>\"        # Project ID\n",
    "MODEL_NAME = \"xgb_model\"         # Model name from previous step\n",
    "VERSION = \"xgb_bst_v0_1\"     # Model version from previous step\n",
    "JSON_TEMP = 'xgb_test_data.json' # temp json file name to hold the inference data\n",
    "batch_size = 1000                # data batch size\n",
    "\n",
    "y_pred = []\n",
    "for ind in range(0, len(x_test), batch_size):\n",
    "    start = ind\n",
    "    end = min(ind+batch_size, len(x_test))\n",
    "    body={'instances': x_test.iloc[start:end].values.tolist()}\n",
    "    with open(JSON_TEMP, 'w') as fp:\n",
    "        json.dump(body, fp)\n",
    "    \n",
    "    predict = !gcloud ai-platform predict \\\n",
    "      --model=$MODEL_NAME \\\n",
    "      --version=$VERSION \\\n",
    "      --format='text' \\\n",
    "      --json-request=$JSON_TEMP \\\n",
    "      --region=$REGION\n",
    "    \n",
    "    y_pred += post_process(predict[1:], end-start, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test['TARGET'].tolist(), y_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
