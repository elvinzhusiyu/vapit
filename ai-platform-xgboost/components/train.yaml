# Copyright 2021 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: Train
inputs:
- {name: job_name, type: String}
- {name: bucket_name, type: String}
- {name: job_folder_name, type: String}
- {name: region, type: String}
- {name: train_feature_path, type: String}
- {name: train_label_path, type: String}
- {name: n_classes, type: Integer}
- {name: n_estimators, type: Integer}
- {name: max_depth, type: Integer}
- {name: booster, type: String}
- {name: config_yaml, type: String, optional: true}
outputs:
- {name: response, type: String}
- {name: job_name, type: String}
implementation:
  container:
    image: gcr.io/img-seg-3d/trainer:v1
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def train(
              job_name,
              bucket_name,
              job_folder_name,
              region,
              train_feature_path,
              train_label_path,
              n_classes,
              n_estimators,
              max_depth,
              booster,
              config_yaml = None,
          ):
          from collections import namedtuple
          import subprocess
          import logging

          job_dir = 'gs://{}/{}/{}'.format(
              bucket_name,
              job_folder_name,
              job_name,
              )
          package_path = "/pipelines/component/trainer"
          module_name = "trainer.train"
          job_config = "/pipelines/component/config/config.yaml"
          logging.info("JOB_NAME = {} ".format(job_name))
          logging.info("JOB_DIR = {} ".format(job_dir))
          logging.info("JOB_CONFIG = {} ".format(job_config))
          # if user input config yaml, then replace the default
          if config_yaml is not None:
              with open(job_config, 'w') as fout:
                  fout.write(config_yaml)

          response = subprocess.run([
              "gcloud", "ai-platform", "jobs", "submit", "training",
              job_name,
              "--job-dir", job_dir,
              "--package-path", package_path,
              "--module-name", module_name,
              "--region", region,
              "--python-version", "3.7",
              "--runtime-version", "2.2",
              "--config", job_config,
              "--",
              "--train_feature_name", train_feature_path,
              "--train_label_name", train_label_path,
              "--no_classes", str(n_classes),
              "--n_estimators", str(n_estimators),
              "--max_depth", str(max_depth),
              "--booster", booster,

          ], stdout=subprocess.PIPE)

          response = subprocess.run([
              "gcloud", "ai-platform", "jobs", "describe", job_name,
          ], stdout=subprocess.PIPE)

          TrainOutput = namedtuple('TrainOutput',['response', 'job_name'])

          return TrainOutput(response=response.stdout.decode(), job_name=job_name)

      def _serialize_str(str_value: str) -> str:
          if not isinstance(str_value, str):
              raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
          return str_value

      import argparse
      _parser = argparse.ArgumentParser(prog='Train', description='')
      _parser.add_argument("--job-name", dest="job_name", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--bucket-name", dest="bucket_name", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--job-folder-name", dest="job_folder_name", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--region", dest="region", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--train-feature-path", dest="train_feature_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--train-label-path", dest="train_label_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--n-classes", dest="n_classes", type=int, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--n-estimators", dest="n_estimators", type=int, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--max-depth", dest="max_depth", type=int, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--booster", dest="booster", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--config-yaml", dest="config_yaml", type=str, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=2)
      _parsed_args = vars(_parser.parse_args())
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = train(**_parsed_args)

      _output_serializers = [
          _serialize_str,
          _serialize_str,

      ]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(_output_serializers[idx](_outputs[idx]))
    args:
    - --job-name
    - {inputValue: job_name}
    - --bucket-name
    - {inputValue: bucket_name}
    - --job-folder-name
    - {inputValue: job_folder_name}
    - --region
    - {inputValue: region}
    - --train-feature-path
    - {inputValue: train_feature_path}
    - --train-label-path
    - {inputValue: train_label_path}
    - --n-classes
    - {inputValue: n_classes}
    - --n-estimators
    - {inputValue: n_estimators}
    - --max-depth
    - {inputValue: max_depth}
    - --booster
    - {inputValue: booster}
    - if:
        cond: {isPresent: config_yaml}
        then:
        - --config-yaml
        - {inputValue: config_yaml}
    - '----output-paths'
    - {outputPath: response}
    - {outputPath: job_name}
