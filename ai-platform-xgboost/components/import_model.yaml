name: Import model
inputs:
- {name: status, type: Boolean}
- {name: bucket_name, type: String}
- {name: job_name, type: String}
- {name: job_folder_name, type: String}
- {name: model_display_name, type: String}
- {name: serving_container_image_uri, type: String, default: 'us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-3:latest',
  optional: true}
outputs:
- {name: model_id, type: String}
implementation:
  container:
    image: gcr.io/img-seg-3d/vertex_base@sha256:2862b83c8b1fd32afddd6be49934f43586ed32c08988a57bb3cef65f5afed750
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - "def import_model(\n    status,\n    bucket_name,\n    job_name,\n    job_folder_name,\n\
      \    model_display_name,\n    serving_container_image_uri = 'us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-3:latest',\n\
      \    ): \n\n    from google.cloud import aiplatform\n    from collections import\
      \ namedtuple\n    import logging\n\n    latest_model_dir = \"gs://{}/{}/{}\"\
      .format(bucket_name, job_folder_name, job_name)\n\n    response = aiplatform.Model.upload(\n\
      \        display_name = model_display_name,\n        serving_container_image_uri\
      \ = serving_container_image_uri,\n        artifact_uri = latest_model_dir\n\
      \    )\n    model_id = response.name.split('/')[-1]\n\n    ImportModelOutput\
      \ = namedtuple('ImportModelOutput',['model_id'])\n    return ImportModelOutput(model_id=model_id)\n\
      \ndef _deserialize_bool(s) -> bool:\n    from distutils.util import strtobool\n\
      \    return strtobool(s) == 1\n\ndef _serialize_str(str_value: str) -> str:\n\
      \    if not isinstance(str_value, str):\n        raise TypeError('Value \"{}\"\
      \ has type \"{}\" instead of str.'.format(str(str_value), str(type(str_value))))\n\
      \    return str_value\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Import\
      \ model', description='')\n_parser.add_argument(\"--status\", dest=\"status\"\
      , type=_deserialize_bool, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --bucket-name\", dest=\"bucket_name\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--job-name\", dest=\"job_name\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--job-folder-name\", dest=\"\
      job_folder_name\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --model-display-name\", dest=\"model_display_name\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--serving-container-image-uri\"\
      , dest=\"serving_container_image_uri\", type=str, required=False, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str,\
      \ nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"\
      _output_paths\", [])\n\n_outputs = import_model(**_parsed_args)\n\n_output_serializers\
      \ = [\n    _serialize_str,\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    args:
    - --status
    - {inputValue: status}
    - --bucket-name
    - {inputValue: bucket_name}
    - --job-name
    - {inputValue: job_name}
    - --job-folder-name
    - {inputValue: job_folder_name}
    - --model-display-name
    - {inputValue: model_display_name}
    - if:
        cond: {isPresent: serving_container_image_uri}
        then:
        - --serving-container-image-uri
        - {inputValue: serving_container_image_uri}
    - '----output-paths'
    - {outputPath: model_id}
