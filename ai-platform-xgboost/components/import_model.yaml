name: Import model
inputs:
- {name: bucket_name, type: String}
- {name: job_folder_name, type: String}
- {name: job_name, type: String}
- {name: model_display_name, type: String}
- {name: serving_container_image_uri, type: String, default: 'us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-3:latest',
  optional: true}
outputs:
- {name: model_id, type: String}
implementation:
  container:
    image: us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-2:latest
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - "def import_model(\n    bucket_name,\n    job_folder_name,\n    job_name,\n\
      \    model_display_name,\n    serving_container_image_uri = 'us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-3:latest',\n\
      \    ): \n\n    from google.cloud import aiplatform\n    from collections import\
      \ namedtuple\n    import logging\n\n    latest_model_dir = \"gs://{}/{}/{}\"\
      .format(bucket_name, job_folder_name, job_name)\n\n    response = aiplatform.Model.upload(\n\
      \        display_name = model_display_name,\n        serving_container_image_uri\
      \ = serving_container_image_uri,\n        artifact_uri = latest_model_dir\n\
      \    )\n    model_id = response.name.split('/')[-1]\n\n    ImportModelOutput\
      \ = namedtuple('ImportModelOutput',['model_id'])\n    return ImportModelOutput(model_id=model_id)\n\
      \ndef _serialize_str(str_value: str) -> str:\n    if not isinstance(str_value,\
      \ str):\n        raise TypeError('Value \"{}\" has type \"{}\" instead of str.'.format(str(str_value),\
      \ str(type(str_value))))\n    return str_value\n\nimport argparse\n_parser =\
      \ argparse.ArgumentParser(prog='Import model', description='')\n_parser.add_argument(\"\
      --bucket-name\", dest=\"bucket_name\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--job-folder-name\", dest=\"job_folder_name\", type=str,\
      \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--job-name\"\
      , dest=\"job_name\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --model-display-name\", dest=\"model_display_name\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--serving-container-image-uri\"\
      , dest=\"serving_container_image_uri\", type=str, required=False, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str,\
      \ nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"\
      _output_paths\", [])\n\n_outputs = import_model(**_parsed_args)\n\n_output_serializers\
      \ = [\n    _serialize_str,\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    args:
    - --bucket-name
    - {inputValue: bucket_name}
    - --job-folder-name
    - {inputValue: job_folder_name}
    - --job-name
    - {inputValue: job_name}
    - --model-display-name
    - {inputValue: model_display_name}
    - if:
        cond: {isPresent: serving_container_image_uri}
        then:
        - --serving-container-image-uri
        - {inputValue: serving_container_image_uri}
    - '----output-paths'
    - {outputPath: model_id}
